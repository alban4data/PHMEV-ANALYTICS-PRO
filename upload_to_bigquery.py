"""
ğŸš€ Script d'upload des donnÃ©es PHMEV vers Google BigQuery
Charge le fichier OPEN_PHMEV_2024.parquet vers BigQuery pour l'application Streamlit
"""

import pandas as pd
from google.cloud import bigquery
from google.oauth2 import service_account
import os
from datetime import datetime

def upload_phmev_to_bigquery():
    """Upload des donnÃ©es PHMEV vers BigQuery"""
    
    print("ğŸš€ DÃ©but de l'upload PHMEV vers BigQuery...")
    
    # Configuration
    PROJECT_ID = 'test-db-473321'
    DATASET_ID = 'dataset'
    TABLE_ID = 'PHMEV2024'
    
    # Chemin du fichier parquet
    script_dir = os.path.dirname(os.path.abspath(__file__))
    parquet_path = os.path.join(script_dir, 'OPEN_PHMEV_2024.parquet')
    
    if not os.path.exists(parquet_path):
        print(f"âŒ Fichier non trouvÃ©: {parquet_path}")
        return False
    
    try:
        # Initialiser le client BigQuery
        print("ğŸ”— Connexion Ã  BigQuery...")
        client = bigquery.Client(project=PROJECT_ID)
        
        # RÃ©fÃ©rence de la table
        table_ref = client.dataset(DATASET_ID).table(TABLE_ID)
        
        # Charger le fichier parquet
        print(f"ğŸ“Š Chargement du fichier parquet: {parquet_path}")
        df = pd.read_parquet(parquet_path, engine='pyarrow')
        
        print(f"âœ… Fichier chargÃ©: {len(df):,} lignes, {len(df.columns)} colonnes")
        
        # Nettoyer les donnÃ©es (identique Ã  la version DuckDB)
        print("ğŸ”„ Nettoyage des donnÃ©es...")
        
        # Filtrer les entrÃ©es non informatives
        df_clean = df[
            (~df['l_cip13'].isin(['Non restituÃ©', 'Non spÃ©cifiÃ©', 'Honoraires de dispensation'])) &
            (df['l_cip13'].notna())
        ].copy()
        
        print(f"âœ… AprÃ¨s nettoyage: {len(df_clean):,} lignes")
        
        # Convertir les types problÃ©matiques
        print("ğŸ”§ Conversion des types de donnÃ©es...")
        
        # Convertir les colonnes ATC en string pour Ã©viter les problÃ¨mes de types mixtes
        atc_columns = ['ATC5', 'atc1', 'atc2', 'atc3', 'atc4']
        for col in atc_columns:
            if col in df_clean.columns:
                df_clean[col] = df_clean[col].astype(str)
        
        # S'assurer que les colonnes financiÃ¨res sont numÃ©riques
        financial_columns = ['REM', 'BSE', 'BOITES']
        for col in financial_columns:
            if col in df_clean.columns:
                df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0)
        
        # Configuration du job d'upload
        job_config = bigquery.LoadJobConfig(
            write_disposition="WRITE_TRUNCATE",  # Remplacer la table existante
            source_format=bigquery.SourceFormat.PARQUET,
            autodetect=True,  # DÃ©tection automatique du schÃ©ma
            max_bad_records=1000  # TolÃ©rer quelques erreurs
        )
        
        print(f"ğŸ“¤ Upload vers BigQuery: {PROJECT_ID}.{DATASET_ID}.{TABLE_ID}")
        print(f"ğŸ“Š Nombre de lignes Ã  uploader: {len(df_clean):,}")
        
        # Lancer le job d'upload
        job = client.load_table_from_dataframe(
            df_clean, 
            table_ref, 
            job_config=job_config
        )
        
        print("â³ Upload en cours...")
        job.result()  # Attendre la fin du job
        
        # VÃ©rifier le rÃ©sultat
        table = client.get_table(table_ref)
        print(f"âœ… Upload terminÃ© avec succÃ¨s!")
        print(f"ğŸ“Š Lignes dans BigQuery: {table.num_rows:,}")
        print(f"ğŸ’¾ Taille de la table: {table.num_bytes / (1024*1024):.1f} MB")
        
        # Test de requÃªte simple
        print("ğŸ§ª Test de requÃªte...")
        test_query = f"""
        SELECT COUNT(*) as total_rows,
               COUNT(DISTINCT nom_etb) as unique_etablissements,
               COUNT(DISTINCT L_ATC5) as unique_medicaments,
               SUM(REM) as total_remboursement
        FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`
        LIMIT 1
        """
        
        result = client.query(test_query).to_dataframe()
        print("ğŸ“Š Statistiques de la table:")
        print(f"   - Lignes totales: {result['total_rows'].iloc[0]:,}")
        print(f"   - Ã‰tablissements uniques: {result['unique_etablissements'].iloc[0]:,}")
        print(f"   - MÃ©dicaments uniques: {result['unique_medicaments'].iloc[0]:,}")
        print(f"   - Remboursement total: {result['total_remboursement'].iloc[0]:,.2f}â‚¬")
        
        print("ğŸ‰ Upload PHMEV vers BigQuery terminÃ© avec succÃ¨s!")
        return True
        
    except Exception as e:
        print(f"âŒ Erreur lors de l'upload: {e}")
        print(f"ğŸ” Type d'erreur: {type(e).__name__}")
        return False

def create_bigquery_views():
    """CrÃ©e des vues optimisÃ©es dans BigQuery"""
    
    print("ğŸ—ï¸ CrÃ©ation des vues optimisÃ©es...")
    
    PROJECT_ID = 'test-db-473321'
    DATASET_ID = 'dataset'
    
    try:
        client = bigquery.Client(project=PROJECT_ID)
        
        # Vue pour les Ã©tablissements
        view_etablissements = f"""
        CREATE OR REPLACE VIEW `{PROJECT_ID}.{DATASET_ID}.vue_etablissements` AS
        SELECT 
            COALESCE(NULLIF(nom_etb, ''), NULLIF(raison_sociale_etb, ''), 'Non spÃ©cifiÃ©') as etablissement,
            COALESCE(NULLIF(categorie_jur, ''), 'Non spÃ©cifiÃ©e') as categorie,
            COALESCE(NULLIF(nom_ville, ''), 'Non spÃ©cifiÃ©e') as ville,
            COALESCE(region_etb, 0) as region,
            SUM(REM) as total_remboursement,
            SUM(BSE) as total_base_remboursable,
            SUM(BOITES) as total_boites,
            COUNT(*) as nb_lignes,
            AVG(CASE WHEN BOITES > 0 THEN REM / BOITES ELSE 0 END) as cout_moyen_par_boite,
            AVG(CASE WHEN BSE > 0 THEN (REM / BSE) * 100 ELSE 0 END) as taux_remboursement_moyen
        FROM `{PROJECT_ID}.{DATASET_ID}.PHMEV2024`
        WHERE l_cip13 NOT IN ('Non restituÃ©', 'Non spÃ©cifiÃ©', 'Honoraires de dispensation')
        AND l_cip13 IS NOT NULL
        GROUP BY etablissement, categorie, ville, region
        """
        
        client.query(view_etablissements).result()
        print("âœ… Vue Ã©tablissements crÃ©Ã©e")
        
        # Vue pour les mÃ©dicaments
        view_medicaments = f"""
        CREATE OR REPLACE VIEW `{PROJECT_ID}.{DATASET_ID}.vue_medicaments` AS
        SELECT 
            COALESCE(NULLIF(L_ATC5, ''), 'Non spÃ©cifiÃ©') as medicament,
            atc1, L_ATC1,
            atc2, L_ATC2,
            atc3, L_ATC3,
            atc4, L_ATC4,
            ATC5, L_ATC5,
            SUM(REM) as total_remboursement,
            SUM(BSE) as total_base_remboursable,
            SUM(BOITES) as total_boites,
            COUNT(*) as nb_lignes,
            COUNT(DISTINCT COALESCE(NULLIF(nom_etb, ''), NULLIF(raison_sociale_etb, ''), 'Non spÃ©cifiÃ©')) as nb_etablissements,
            AVG(CASE WHEN BOITES > 0 THEN REM / BOITES ELSE 0 END) as cout_moyen_par_boite,
            AVG(CASE WHEN BSE > 0 THEN (REM / BSE) * 100 ELSE 0 END) as taux_remboursement_moyen
        FROM `{PROJECT_ID}.{DATASET_ID}.PHMEV2024`
        WHERE l_cip13 NOT IN ('Non restituÃ©', 'Non spÃ©cifiÃ©', 'Honoraires de dispensation')
        AND l_cip13 IS NOT NULL
        GROUP BY medicament, atc1, L_ATC1, atc2, L_ATC2, atc3, L_ATC3, atc4, L_ATC4, ATC5, L_ATC5
        """
        
        client.query(view_medicaments).result()
        print("âœ… Vue mÃ©dicaments crÃ©Ã©e")
        
        print("ğŸ‰ Toutes les vues ont Ã©tÃ© crÃ©Ã©es avec succÃ¨s!")
        return True
        
    except Exception as e:
        print(f"âŒ Erreur lors de la crÃ©ation des vues: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ¥ PHMEV Analytics Pro - Upload BigQuery")
    print("=" * 50)
    
    # Ã‰tape 1: Upload des donnÃ©es
    success = upload_phmev_to_bigquery()
    
    if success:
        # Ã‰tape 2: CrÃ©ation des vues optimisÃ©es
        create_bigquery_views()
        
        print("\nğŸ‰ Configuration BigQuery terminÃ©e!")
        print("\nğŸ“‹ Prochaines Ã©tapes:")
        print("1. Configurer les credentials dans Streamlit Cloud")
        print("2. Remplacer streamlit_app.py par streamlit_app_bigquery.py")
        print("3. DÃ©ployer sur Streamlit Cloud")
        print("\nğŸš€ Votre application sera ultra-performante avec BigQuery!")
    else:
        print("\nâŒ Ã‰chec de l'upload. VÃ©rifiez les credentials et la configuration.")
